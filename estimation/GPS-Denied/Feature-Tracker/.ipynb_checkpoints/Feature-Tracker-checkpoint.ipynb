{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Tracker\n",
    "\n",
    "In this notebook you'll determine _good_ image features to track using [OpenCV](https://opencv.org/). There are many suitable algorithms, among them the *Shi-Tomasi* feature detector. While ths amounts to adding a couple of lines of code, there are several paramters to set which greatly imapact the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from moviepy.editor import ImageSequenceClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 12, 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the video clip. The video from the downward facing camera of the drone San Francisco simulator environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = imageio.get_reader('vid.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the first frame of the clip, you can use this to quickly iterate on your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = reader.get_data(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [`cv.goodFeaturesToTrack`](https://docs.opencv.org/3.4.1/dd/d1a/group__imgproc__feature.html#ga1d6bb77486c8f92d79c8793ad995d541) to retrieve features using *Shi-Tomasi*. You'll notice `feature_params` below, feel free to change the values. If you're not sure what role a value plays read the docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set the feature params\n",
    "feature_params = dict(maxCorners=?,  # no limit on number of corners\n",
    "                      qualityLevel=?,\n",
    "                      minDistance=?,\n",
    "                      blockSize=?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(reader):\n",
    "    frames = []\n",
    "\n",
    "    # NOTE: You may want to limit this for loop\n",
    "    # to a shorter range at first.\n",
    "    for i in range(reader.get_length()):\n",
    "        frame = reader.get_data(i)\n",
    "        corners = shi_tomasi(frame)\n",
    "        \n",
    "        if corners is None or len(corners) == 0:\n",
    "            continue\n",
    "            \n",
    "        corners = np.reshape(corners, (-1, 2)).astype(int)\n",
    "                \n",
    "        for ind in corners:\n",
    "            # draws a white circle at a feature location\n",
    "            frame = cv.circle(frame, (ind[0], ind[1]), 5, [255, 255, 255], -1)\n",
    "        \n",
    "        frames.append(frame)\n",
    "        \n",
    "    return frames\n",
    "\n",
    "def shi_tomasi(img):\n",
    "    # TODO: complete the implementation\n",
    "    # return best pixels to track according to Shi-Tomasi\n",
    "    \n",
    "    # image must converted to grayscale prior to detecting features\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    corners = ?\n",
    "\n",
    "    return corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time frames = transform(reader)\n",
    "print(len(frames), frames[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the frames into a movie, just like in Hollywood :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = ImageSequenceClip(frames, fps=30)\n",
    "clip.ipython_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Solution](./Feature-Tracker-Solution.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

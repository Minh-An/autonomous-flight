{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Flow\n",
    "\n",
    "In this notebook you'll use *Optical Flow* to track features produced by *Shi-Tomasi*, predicting where the features will be in the next frame. This difference in pixel location is the velocity measured in pixels/frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 12, 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to *Shi-Tomasi*, the *Optical Flow* algorithm has many tunable paramters. We'll be using [cv.calcOpticalFlowPyrLK](https://docs.opencv.org/3.4.1/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323) which uses the *Lucas-Kanade* method. Once again, there are several parameters to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Shi Tamasi features\n",
    "feature_params = dict(maxCorners=0,  # no limit on number of corners\n",
    "                      qualityLevel=0.05,\n",
    "                      minDistance=50,\n",
    "                      blockSize=7)\n",
    "\n",
    "# Parameters for Lucas Kanade optical flow\n",
    "optical_flow_params = dict(winSize=(?, ?),\n",
    "                           maxLevel=?, \n",
    "                           criteria=(?, ?, ?))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to shorten the loop in `track` while you're fiddling with the parameters since it'll shorten the time to create the video, and hence the development time. Also note the `detect_interval` argument, by default corners are redetected on every 5th frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shi_tomasi(img):\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    return cv.goodFeaturesToTrack(gray, **feature_params)\n",
    "\n",
    "\n",
    "def optical_flow(frame0, frame1, corners0):        \n",
    "    # convert images to grayscale\n",
    "    frame0_gray = cv.cvtColor(frame0, cv.COLOR_BGR2GRAY)\n",
    "    frame1_gray = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # TODO: Use the Lucas-Kanade method `cv.calcOpticalFlowPyrLK` for Optical Flow\n",
    "    # Indices of the `status` array which equal 1 signify a corresponding new feature has been found\n",
    "    corners1, status, err = ?\n",
    "    \n",
    "    return corners1, status==1\n",
    "    \n",
    "\n",
    "def track(reader, detect_interval=5):\n",
    "    frames = []\n",
    "    \n",
    "    frame0 = reader.get_data(0)\n",
    "    \n",
    "    # Initial corners, after this we'll detect\n",
    "    # corners on the interval `detect_interval`\n",
    "    corners0 = shi_tomasi(frame0)\n",
    "    \n",
    "    mean_u = 0\n",
    "    mean_v = 0\n",
    "    \n",
    "    # Used for weighted average update of the velocity\n",
    "    alpha = 0.97\n",
    "        \n",
    "    # NOTE: You may want to limit this for loop\n",
    "    # to a shorter range at first.\n",
    "    for i in range(1, reader.get_length()):\n",
    "        frame1 = reader.get_data(i)\n",
    "        # for visualization\n",
    "        vis = frame1.copy()         \n",
    "        \n",
    "        corners1, valid = optical_flow(frame0, frame1, corners0)\n",
    "        \n",
    "        # This discards any pixels from `corners0` which did not\n",
    "        # produce a corresponding pixel with optical flow\n",
    "        velocity = ((corners1 - corners0)[valid==1]).reshape(-1, 2)\n",
    "        \n",
    "        # TODO: calculate mean velocity in pixels/frame\n",
    "        u, v = ?\n",
    "        \n",
    "        # NOTE: we use a simple weighted average method\n",
    "        # but you may want to use some of the\n",
    "        # estimation techniques you've learned.\n",
    "        mean_u = alpha * mean_u + (1-alpha) * np.mean(u)\n",
    "        mean_v = alpha * mean_v + (1-alpha) * np.mean(v)\n",
    "        \n",
    "        # Velocity related visuals\n",
    "        cv.putText(vis, \"Mean X Velocity (U) = {0:.2f}\".format(mean_u), \n",
    "                   (20, 20), cv.FONT_HERSHEY_PLAIN, 1.0, (255, 255, 255), thickness=2, lineType=cv.LINE_AA)\n",
    "        cv.putText(vis, \"Mean Y Velocity (V) = {0:.2f}\".format(mean_v), \n",
    "                   (20, 35), cv.FONT_HERSHEY_PLAIN, 1.0, (255, 255, 255), thickness=2, lineType=cv.LINE_AA)\n",
    "        vis = cv.arrowedLine(vis, (50, 100), (int(50+5*mean_u), int(100-5*mean_v)), \n",
    "                             (0, 255, 0), 2, tipLength=0.3, line_type=cv.LINE_AA)\n",
    "\n",
    "        # carry over new corners\n",
    "        corners0 = corners1\n",
    "        \n",
    "        # refresh corners\n",
    "        # If we only relied on corners carrying over\n",
    "        # we would eventually run out of corners\n",
    "        if i % detect_interval == 0:\n",
    "            corners0 = shi_tomasi(frame0)\n",
    "    \n",
    "        frame0 = frame1\n",
    "        frames.append(vis)\n",
    "        \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = imageio.get_reader('vid.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time frames = track(reader, detect_interval=5)\n",
    "print(len(frames), frames[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = ImageSequenceClip(frames, fps=24)\n",
    "clip.ipython_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Solution](./Optical-Flow-Solution.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

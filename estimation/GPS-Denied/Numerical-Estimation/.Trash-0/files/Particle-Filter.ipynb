{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Filter\n",
    "\n",
    "In this notebook you'll combine code from the previous notebooks and implement a particle filter. In pseudocode the particle filter algorithm is:\n",
    "\n",
    "```\n",
    "particles = sample N times from prior distribution\n",
    "for t in range(timesteps):\n",
    "    # from Numerical Estimation\n",
    "    particles = propagate distribution with the vehicle model\n",
    "    # from Sensor Fusion\n",
    "    weights = estimate probability/weights of particles via sensor fusion\n",
    "    particles = sample new particles from the weighted distribution\n",
    "```\n",
    "\n",
    "The final distribution resemble the actual state of the vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from bresenham import bresenham\n",
    "from utils import create_grid, valid_location, inbounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 13, 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('colliders.csv', delimiter=',', dtype='Float64', skiprows=2)\n",
    "grid, _, _ = create_grid(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code based on previous notebooks.\n",
    "\n",
    "**NOTE: You'll notice if there's prior knowledge of the state, the $\\theta$ of samples is centered around the passed state's $\\theta$ value, otherwise it's sampled from [0, 360] degrees.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Esitmation Code\n",
    "\n",
    "def sample_from_prior(grid_map, N, state=None):\n",
    "    samples = []\n",
    "    \n",
    "    while len(samples) < N:\n",
    "        x = np.random.uniform(0, grid.shape[1])\n",
    "        y = np.random.uniform(0, grid.shape[0])\n",
    "       \n",
    "        # Feel free to alter this distribution\n",
    "        if state is None:\n",
    "            theta = np.random.uniform(-np.pi, np.pi)\n",
    "        else:\n",
    "            theta = np.random.normal(state[2], np.radians(0.5))\n",
    "            \n",
    "        s = [x, y, theta]\n",
    "        if valid_location(grid_map, int(x), int(y)):\n",
    "            samples.append(s)\n",
    "            \n",
    "    return np.array(samples)\n",
    "\n",
    "def simulate(state, angle=np.radians(0), v=5, dt=1):\n",
    "    x, y, theta = state\n",
    "    \n",
    "    w = [np.random.normal(), np.random.normal(), np.random.normal(0, 0.015)]\n",
    "    \n",
    "    x_new = x + v*np.cos(theta)*dt + w[0]\n",
    "    y_new = y + v*np.sin(theta)*dt + w[1]\n",
    "    theta_new = theta + v*np.tan(angle)*dt + w[2]\n",
    "    \n",
    "    return np.array([x_new, y_new, theta_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensor Fusion Code\n",
    "\n",
    "class LidarSensor:\n",
    "    def __init__(self, max_range):\n",
    "        self._max_range = max_range\n",
    "        \n",
    "    @property\n",
    "    def max_range(self):\n",
    "        return self._max_range\n",
    "    \n",
    "    def _random_measure(self):\n",
    "        return np.random.randint(0, self._max_range+1)\n",
    "    \n",
    "    def _failure_measure(self):\n",
    "        return self._max_range\n",
    "    \n",
    "    def _hit_measure(self, expected_dist):\n",
    "        return np.random.normal(expected_dist)\n",
    "    \n",
    "    def measure(self, expected_dist):\n",
    "        p = np.random.rand()\n",
    "        if p <= 0.95:\n",
    "            return self._hit_measure(expected_dist)\n",
    "        elif p <= 0.98:\n",
    "            return self._random_measure()\n",
    "        return self._failure_measure()\n",
    "    \n",
    "    def lookup_prob(self, expected_dist, measured_dist):\n",
    "        norm_prob = 0.95 * stats.norm.pdf(measured_dist, loc=expected_dist)\n",
    "        random_prob = 0.03 * (1 / self._max_range)\n",
    "        failure_prob = 0\n",
    "        if measured_dist == self._max_range:\n",
    "            failure_prob = 0.02\n",
    "        return norm_prob + random_prob + failure_prob\n",
    "    \n",
    "def sense(grid, sensor, ground_truth_state, rays):\n",
    "    \"\"\"Generate a number of sensor measurements, `rays` from the ground truth\n",
    "    state `ground_truth_state`.\n",
    "    \"\"\"\n",
    "    measured_distances = []\n",
    "    dists = shoot_rays(grid, sensor, ground_truth_state, k=rays)\n",
    "    for d in dists:\n",
    "        measured_distances.append(sensor.measure(d))\n",
    "    return measured_distances\n",
    "\n",
    "def sensor_fusion(grid_map, sensor, samples, measured_distances):\n",
    "    \"\"\"Given sampled states, `samples` and ground truth sensor\n",
    "    distance measurements, `measured_distances` return the new mean\n",
    "    state and standard deviation estimates.\n",
    "    \"\"\"\n",
    "    weights = []\n",
    "    for s in samples:\n",
    "        weight = importance(grid_map, sensor, s, measured_distances)\n",
    "        weights.append(weight)\n",
    "        \n",
    "    # normalize weights\n",
    "    weights = np.array(weights)\n",
    "    weights /= np.sum(weights)\n",
    "        \n",
    "    return np.array(weights)\n",
    "\n",
    "def shoot_rays(grid_map, sensor, state, k):\n",
    "    \"\"\"\n",
    "    Shoot `k` number of rays the given state, `state`.\n",
    "    The rays will be evenly spaced.\n",
    "    \"\"\"\n",
    "    x, y, theta = state\n",
    "    expected_distances = []\n",
    "    for i, bearing in enumerate(range(k)):\n",
    "        bearing = bearing * (360 / k)\n",
    "        angle = (theta + np.radians(bearing)) % (2 * np.pi)\n",
    "        expected_dist, _ = get_distance(grid_map, sensor, x, y, angle)\n",
    "        expected_distances.append(expected_dist)\n",
    "    return expected_distances\n",
    "\n",
    "def importance(grid_map, sensor, state, measured_distances):\n",
    "    \"\"\"Returns the \"importance\" of the sampled `state` based\n",
    "    on a comparison between the `measured_distances` and the\n",
    "    distances measured from the sampled state.\n",
    "    \"\"\"\n",
    "    expected_distances = shoot_rays(grid_map, sensor, state, k=len(measured_distances))\n",
    "    weight = 1\n",
    "    \n",
    "    for (ed, md) in zip(expected_distances, measured_distances):\n",
    "        weight *= sensor.lookup_prob(ed, md)\n",
    "        \n",
    "    return weight\n",
    "\n",
    "\n",
    "def get_distance(grid_map, sensor, x, y, angle):\n",
    "    \"\"\"Uses bresenham to find the distance to the nearest\n",
    "    obstacle on the map from an observation at x, y pointed\n",
    "    in a certain angle. If no obstacle is hit the max sensor range\n",
    "    is returned.\"\"\"        \n",
    "    x2 = x + sensor.max_range * np.cos(angle)\n",
    "    y2 = y + sensor.max_range * np.sin(angle)\n",
    "    \n",
    "    cells = bresenham(int(x), int(y), int(x2), int(y2))\n",
    "            \n",
    "    dist = sensor.max_range\n",
    "    loc = [x2, y2]\n",
    "    \n",
    "    for c in cells:\n",
    "        if not inbounds(grid_map, c[0], c[1]):\n",
    "            return dist, loc\n",
    "        \n",
    "        if grid_map[c[1], c[0]] == 1:\n",
    "            dist = np.linalg.norm(np.array([x, y]) - np.array([c[0], c[1]]))\n",
    "            loc = [c[0], c[1]]\n",
    "            break\n",
    "            \n",
    "    return dist, loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_particles = 2000\n",
    "max_sensor_range = 100\n",
    "sensor = LidarSensor(max_sensor_range)\n",
    "\n",
    "# initial state\n",
    "init_ground_truth_state = [385, 450, np.radians(45)]\n",
    "init_samples = sample_from_prior(grid, num_particles, init_ground_truth_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(grid, origin='lower', cmap='Greys')\n",
    "plt.plot(init_ground_truth_state[0], init_ground_truth_state[1], 'ro')\n",
    "plt.plot(init_samples[:, 0], init_samples[:, 1], 'bo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the particle filter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def particle_filter(grid, sensor, ground_truth_state, samples, n_timesteps, rays):  \n",
    "    samples = np.copy(samples)\n",
    "    ground_truth_state = np.copy(ground_truth_state)\n",
    "    \n",
    "    # TODO: complete implementation\n",
    "    # make sure to propagate the ground truth state along with the\n",
    "    # distribution samples\n",
    "    \n",
    "    return samples, ground_truth_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may take a while ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of timesteps to propagate forward\n",
    "n_timesteps = 5\n",
    "# number to shoot from Lidar, these are evenly spread from 0 to 360.\n",
    "rays = 16\n",
    "\n",
    "%time samples, ground_truth_state = particle_filter(grid, sensor, init_ground_truth_state, init_samples, n_timesteps, rays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final samples (blue dots) should be very close to the green dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(grid, origin='lower', cmap='Greys')\n",
    "\n",
    "# blue dots sampled from the final weighted distribution\n",
    "plt.plot(samples[:, 0], samples[:, 1], 'bo')\n",
    "\n",
    "# red dot is initial position\n",
    "plt.plot(init_ground_truth_state[0], init_ground_truth_state[1], 'ro')\n",
    "\n",
    "# green dot is new simulated position\n",
    "plt.plot(ground_truth_state[0], ground_truth_state[1], 'go')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Solution](./Particle-Filter-Solution.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
